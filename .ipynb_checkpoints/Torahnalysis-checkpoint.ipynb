{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torah scraping\n",
    "\n",
    "### Looking for hidden patterns.\n",
    "### and not so hidden patterns.\n",
    "### 2020-4-21\n",
    "### Joe Hostyk and Alex Zaloum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c22369b3fbd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# matplotlib.use('TKAgg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# cbook must import matplotlib only within function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m from matplotlib.cbook import (\n\u001b[1;32m    129\u001b[0m     _backports, mplDeprecation, dedent, get_label, sanitize_sequence)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mweakref\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeakKeyDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;34m\"numpy in {}. One method of fixing this is to repeatedly uninstall \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"numpy until none is found, then reinstall this version.\")\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumerictypes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('TKAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMATRIA = {\"א\": 1, \"ב\": 2, \"ג\": 3, \"ד\": 4, \"ה\": 5, \"ו\": 6, \"ז\": 7, \"ח\": 8, \"ט\": 9, \"י\": 10, \"כ\": 20, \"ך\": 20, \"ל\": 30, \"מ\": 40, \"ם\": 40, \"נ\": 50, \"ן\": 50, \"ס\": 60, \"ע\": 70, \"פ\": 80, \"ף\": 80, \"צ\": 90, \"ץ\": 90, \"ק\": 100, \"ר\": 200, \"ש\": 300, \"ת\": 400}\n",
    "ALEPH_BEIS = GMATRIA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: sofit letters\n",
    "## Define the otiyot categories\n",
    "## Different breakdowns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting filenames...\n",
      "vayikra\n",
      "dvarim\n",
      "breishit\n",
      "shmot\n",
      "bamidbar\n"
     ]
    }
   ],
   "source": [
    "def getFileNames(folder):\n",
    "    \"\"\"\n",
    "    Get all our file names for processing later.\n",
    "    Currently, doesn't recursively search.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Full path to the folder.\n",
    "\n",
    "    Returns:\n",
    "        filenames (list of strings)\n",
    "    \"\"\"\n",
    "\n",
    "    print (\"Getting filenames...\")\n",
    "\n",
    "    filenames = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \".txt\" in file:\n",
    "            filenames.append(os.path.join(folder, file))\n",
    "    return filenames\n",
    "\n",
    "def makeWordDictionaryFromSefer(filename):\n",
    "    \n",
    "    seferWords = Counter()\n",
    "    with open(filename, \"r\") as psukim:\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    seferWords[word] += 1\n",
    "                except KeyError as e:\n",
    "                    problematicWords.add(word)\n",
    "    return seferWords\n",
    "\n",
    "\n",
    "def makeLetterDictionaryFromSefer(filename, allLetters):\n",
    "    \n",
    "    with open(filename, \"r\") as psukim:\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    for letter in word:\n",
    "                        allLetters[letter] += 1\n",
    "                except KeyError as e:\n",
    "                    problematicWords.add(word)\n",
    "    return allLetters  \n",
    "\n",
    "def makeNgramsDictionaryFromSefer(filename, allNgrams, sizeOfngram):\n",
    "    \n",
    "    with open(filename, \"r\") as psukim:\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    for letterIndex in range(len(word) - sizeOfngram + 1):\n",
    "    \n",
    "                        ngram = word[letterIndex:letterIndex + sizeOfngram]\n",
    "                        allNgrams[ngram] += 1\n",
    "                except KeyError as e:\n",
    "                    problematicWords.add(word)\n",
    "    return allNgrams  \n",
    "\n",
    "def getAllFiles(filenames):\n",
    "    \n",
    "    allWords = {}\n",
    "    allLetters = Counter()\n",
    "    allNgrams = Counter()\n",
    "    \n",
    "    for filename in filenames:\n",
    "        \n",
    "        seferName = filename.replace(\".txt\", \"\").split(\"/\")[-1]\n",
    "        print(seferName)\n",
    "#         allWords[seferName] = makeDictionaryFromSefer(filename)\n",
    "#         allLetters = makeLetterDictionaryFromSefer(filename, allLetters)\n",
    "        allNgrams = makeNgramsDictionaryFromSefer(filename, allNgrams, sizeOfngram = 2)\n",
    "\n",
    "#         raise\n",
    "    return allNgrams\n",
    "        \n",
    "        \n",
    "folder = \"./texts\"\n",
    "filenames = getFileNames(folder)\n",
    "# allWords = getAllFiles(filenames)\n",
    "# allLetters = getAllFiles(filenames)\n",
    "allNgrams = getAllFiles(filenames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which pairs never show up in the Torah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPossiblePairs = list(itertools.product(ALEPH_BEIS, ALEPH_BEIS))\n",
    "allPossiblePairs = [\"\".join(pair) for pair in allPossiblePairs]\n",
    "# allPossiblePairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['בף', 'גט', 'גכ', 'גס', 'גצ', 'גץ', 'גק', 'דז', 'דט', 'דס', 'דצ', 'דץ', 'הף', 'הץ', 'זט', 'זס', 'זף', 'זצ', 'זץ', 'זש', 'חא', 'חע', 'טג', 'טז', 'טכ', 'טס', 'טצ', 'טץ', 'טק', 'כץ', 'ךא', 'ךב', 'ךג', 'ךד', 'ךה', 'ךו', 'ךז', 'ךח', 'ךט', 'ךי', 'ךכ', 'ךך', 'ךל', 'ךמ', 'ךם', 'ךנ', 'ךן', 'ךס', 'ךע', 'ךפ', 'ךף', 'ךצ', 'ךץ', 'ךק', 'ךר', 'ךש', 'ךת', 'מף', 'םא', 'םב', 'םג', 'םד', 'םה', 'םו', 'םז', 'םח', 'םט', 'םי', 'םכ', 'םך', 'םל', 'םמ', 'םם', 'םנ', 'םן', 'םס', 'םע', 'םפ', 'םף', 'םצ', 'םץ', 'םק', 'םר', 'םש', 'םת', 'ןא', 'ןב', 'ןג', 'ןד', 'ןה', 'ןו', 'ןז', 'ןח', 'ןט', 'ןי', 'ןכ', 'ןך', 'ןל', 'ןמ', 'ןם', 'ןנ', 'ןן', 'ןס', 'ןע', 'ןפ', 'ןף', 'ןצ', 'ןץ', 'ןק', 'ןר', 'ןש', 'ןת', 'סז', 'סט', 'סצ', 'סץ', 'סש', 'עח', 'עע', 'עף', 'פב', 'פפ', 'ףא', 'ףב', 'ףג', 'ףד', 'ףה', 'ףו', 'ףז', 'ףח', 'ףט', 'ףי', 'ףכ', 'ףך', 'ףל', 'ףמ', 'ףם', 'ףנ', 'ףן', 'ףס', 'ףע', 'ףפ', 'ףף', 'ףצ', 'ףץ', 'ףק', 'ףר', 'ףש', 'ףת', 'צז', 'צס', 'צש', 'ץא', 'ץב', 'ץג', 'ץד', 'ץה', 'ץו', 'ץז', 'ץח', 'ץט', 'ץי', 'ץכ', 'ץך', 'ץל', 'ץמ', 'ץם', 'ץנ', 'ץן', 'ץס', 'ץע', 'ץפ', 'ץף', 'ץצ', 'ץץ', 'ץק', 'ץר', 'ץש', 'ץת', 'קג', 'קז', 'שצ', 'שץ']\n"
     ]
    }
   ],
   "source": [
    "print([pair for pair in allPossiblePairs if pair not in allNgrams])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most common pairs in the Torah?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('את', 5543), ('וי', 4352), ('אל', 4090), ('ים', 3970), ('יה', 3734)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allNgrams.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('טד', 5),\n",
       " ('סס', 5),\n",
       " ('קא', 4),\n",
       " ('כט', 4),\n",
       " ('קף', 4),\n",
       " ('זם', 4),\n",
       " ('חף', 3),\n",
       " ('א\\u200d', 3),\n",
       " ('\\u200dש', 3),\n",
       " ('זך', 3),\n",
       " ('שף', 3),\n",
       " ('עס', 3),\n",
       " ('זח', 3),\n",
       " ('קק', 3),\n",
       " ('אט', 3),\n",
       " ('פמ', 3),\n",
       " ('נץ', 2),\n",
       " ('תץ', 2),\n",
       " ('לץ', 2),\n",
       " ('פף', 2),\n",
       " ('זפ', 2),\n",
       " ('צץ', 2),\n",
       " ('טט', 1),\n",
       " ('אץ', 1),\n",
       " ('סן', 1),\n",
       " ('אא', 1),\n",
       " ('צט', 1),\n",
       " ('קכ', 1),\n",
       " ('הך', 1),\n",
       " ('זג', 1)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Most common:\n",
    "allNgrams.most_common(575)\n",
    "\n",
    "### Least common:\n",
    "allNgrams.most_common(575)[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([27.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.]),\n",
       " array([    3,    70,    70,   830,  1035,  1806,  1836,  2111,  2199,\n",
       "         2937,  3358,  3976,  4260,  4700,  7039,  7194,  8614,  9889,\n",
       "        10630, 11270, 14474, 15605, 16357, 17965, 18147, 21583, 27069,\n",
       "        28085, 30596, 31607]),\n",
       " <a list of 29 Patch objects>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortedLetters = {k: v for k, v in sorted(allLetters.items(), key=lambda item: item[1])}\n",
    "\n",
    "plt.hist(list(sortedLetters.keys()), list(sortedLetters.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get gmatrias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmatrifyAword(word):\n",
    "    \"\"\"\n",
    "    Get the gmatria for one word. Doesn't catch punctuation/errors.\n",
    "\n",
    "    Args:\n",
    "        word (str)\n",
    "\n",
    "    Returns:\n",
    "        The gmatria (int)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return sum([GMATRIA[letter] for letter in word])\n",
    "\n",
    "# Numbers, to words with that gmatria\n",
    "\n",
    "def getGmatrias():\n",
    "    \n",
    "    gmatriasToWords = {}\n",
    "\n",
    "    directory = \"./texts/\"\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(\"./texts\")\n",
    "    \n",
    "    pathToGmatriaFile = \"{}bamidbarGmatriaByNumber.tsv\".format(directory)\n",
    "\n",
    "    if os.path.exists(pathToGmatriaFile):\n",
    "        print (\"Gmatria file exists. Reading...\")\n",
    "        reader = csv.reader(open(pathToGmatriaFile), delimiter = \"\\t\")\n",
    "        header = next(reader)\n",
    "        for line in reader:\n",
    "            line = dict(zip(header, line))\n",
    "            word = int(line[\"Gmatria\"])\n",
    "            shifts = set(line[\"Word\"].split(\" | \"))\n",
    "            gmatriasToWords[word] = shifts\n",
    "        print (\"Finished reading.\")\n",
    "    ### To-do: fill this in later\n",
    "#     else:\n",
    "#         print (\"Gmatria file does not exist. Creating...\")\n",
    "#         with open(pathToGmatriaFile, \"w\") as out:\n",
    "\n",
    "#             out.write(\"Gmatria\\tWord\\n\")\n",
    "\n",
    "#             \n",
    "    return gmatriasToWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gmatria file exists. Reading...\n",
      "Finished reading.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'הארדי', 'וטהר', 'וידר', 'וירד', 'ורוח', 'טהור', 'יבחר', 'צפים', 'רוחו'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmatriasToWords = getGmatrias()\n",
    "gmatriasToWords[220]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic histogram/breakdowns:\n",
    "    \n",
    "#### Letters, pairs of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
