{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torah scraping\n",
    "\n",
    "### Looking for hidden patterns.\n",
    "### and not so hidden patterns.\n",
    "### 2020-4-21\n",
    "### Joe Hostyk and Alex Zaloum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import itertools\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMATRIA = {\"א\": 1, \"ב\": 2, \"ג\": 3, \"ד\": 4, \"ה\": 5, \"ו\": 6, \"ז\": 7, \"ח\": 8, \"ט\": 9, \"י\": 10, \"כ\": 20, \"ך\": 20, \"ל\": 30, \"מ\": 40, \"ם\": 40, \"נ\": 50, \"ן\": 50, \"ס\": 60, \"ע\": 70, \"פ\": 80, \"ף\": 80, \"צ\": 90, \"ץ\": 90, \"ק\": 100, \"ר\": 200, \"ש\": 300, \"ת\": 400}\n",
    "ALEPH_BEIS = GMATRIA.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilePaths(folder, additionalSearch = \"\", hebrewOrEnglish = \"Hebrew\"):\n",
    "    \"\"\"\n",
    "    Recursively go through a folder and get all file names, for processing later.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Full path to the folder.\n",
    "        additionalSearch (str): Optional extra term in the file name. Useful for some\n",
    "            Sefaria names. For gmara, \"merged.txt\" seemed to be the best Hebrew version.\n",
    "            For Tanach, \"Text Only.txt\" was a non-nekudot, good version.\n",
    "        hebrewOrEnglish (str): We saved a Hebrew and English version for each sefer. The\n",
    "            user can specify which to load. Defaults to Hebrew.\n",
    "\n",
    "    Returns:\n",
    "        filePaths (list of strings): \n",
    "    \"\"\"\n",
    "\n",
    "    print (\"Getting file paths...\")\n",
    "\n",
    "    filePaths = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if \".txt\" in file and hebrewOrEnglish in root and additionalSearch in file:\n",
    "                filePaths.append(os.path.join(root, file))\n",
    "    return filePaths\n",
    "\n",
    "def getAllTanachPaths():\n",
    "    \"\"\"\n",
    "    Get all the links at once.\n",
    "\n",
    "    Returns:\n",
    "        tanachPaths (dict): {\"Torah\": [paths to Torah sfarim], \"Neviyim\": [...], \"Ktuvim\": [...]}\n",
    "    \"\"\"   \n",
    "    \n",
    "    tanachPaths = dict()\n",
    "    \n",
    "    sections = [\"Torah\", \"Neviyim\", \"Ktuvim\"]\n",
    "    for section in sections:\n",
    "        tanachPaths[section] = getFilePaths(\"Texts/{}\".format(section), additionalSearch = \"Text Only\")\n",
    "\n",
    "    return tanachPaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeWordDictionaryFromSefer(filePath):\n",
    "    \n",
    "    seferWords = Counter()\n",
    "    with open(filePath, \"r\") as psukim:\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    seferWords[word] += 1\n",
    "                except KeyError as e:\n",
    "                    problematicWords.add(word)\n",
    "    return seferWords\n",
    "\n",
    "\n",
    "def makeLetterDictionaryFromSefer(filePath, allLetters):\n",
    "    \n",
    "    with open(filePath, \"r\") as psukim:\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    for letter in word:\n",
    "                        allLetters[letter] += 1\n",
    "                except KeyError as e:\n",
    "                    problematicWords.add(word)\n",
    "    return allLetters  \n",
    "\n",
    "def makeNgramsDictionaryFromSefer(filePath, allNgrams, sizeOfngram):\n",
    "    \n",
    "    with open(filePath, \"r\") as psukim:\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    for letterIndex in range(len(word) - sizeOfngram + 1):\n",
    "    \n",
    "                        ngram = word[letterIndex:letterIndex + sizeOfngram]\n",
    "                        allNgrams[ngram] += 1\n",
    "                except KeyError as e:\n",
    "                    problematicWords.add(word)\n",
    "    return allNgrams  \n",
    "\n",
    "def getAllFiles(filePaths):\n",
    "    \n",
    "    allWords = {}\n",
    "    allLetters = Counter()\n",
    "    allNgrams = Counter()\n",
    "    \n",
    "    for filePath in filePaths:\n",
    "        \n",
    "        seferName = filePath.replace(\".txt\", \"\").split(\"/\")[-1]\n",
    "        print(seferName)\n",
    "#         allWords[seferName] = makeDictionaryFromSefer(filename)\n",
    "#         allLetters = makeLetterDictionaryFromSefer(filename, allLetters)\n",
    "        allNgrams = makeNgramsDictionaryFromSefer(filePath, allNgrams, sizeOfngram = 2)\n",
    "\n",
    "#         raise\n",
    "    return allNgrams\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting filenames...\n"
     ]
    }
   ],
   "source": [
    "folder = \"./texts/Torah\"\n",
    "filePaths = getFilePaths(folder, additionalSearch = \"Text Only\")\n",
    "filePaths\n",
    "# allWords = getAllFiles(filenames)\n",
    "# allLetters = getAllFiles(filenames)\n",
    "# allNgrams = getAllFiles(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which pairs never show up in the Torah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPossiblePairs = list(itertools.product(ALEPH_BEIS, ALEPH_BEIS))\n",
    "allPossiblePairs = [\"\".join(pair) for pair in allPossiblePairs]\n",
    "# allPossiblePairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['בף', 'גט', 'גכ', 'גס', 'גצ', 'גץ', 'גק', 'דז', 'דט', 'דס', 'דצ', 'דץ', 'הף', 'הץ', 'זט', 'זס', 'זף', 'זצ', 'זץ', 'זש', 'חא', 'חע', 'טג', 'טז', 'טכ', 'טס', 'טצ', 'טץ', 'טק', 'כץ', 'ךא', 'ךב', 'ךג', 'ךד', 'ךה', 'ךו', 'ךז', 'ךח', 'ךט', 'ךי', 'ךכ', 'ךך', 'ךל', 'ךמ', 'ךם', 'ךנ', 'ךן', 'ךס', 'ךע', 'ךפ', 'ךף', 'ךצ', 'ךץ', 'ךק', 'ךר', 'ךש', 'ךת', 'מף', 'םא', 'םב', 'םג', 'םד', 'םה', 'םו', 'םז', 'םח', 'םט', 'םי', 'םכ', 'םך', 'םל', 'םמ', 'םם', 'םנ', 'םן', 'םס', 'םע', 'םפ', 'םף', 'םצ', 'םץ', 'םק', 'םר', 'םש', 'םת', 'ןא', 'ןב', 'ןג', 'ןד', 'ןה', 'ןו', 'ןז', 'ןח', 'ןט', 'ןי', 'ןכ', 'ןך', 'ןל', 'ןמ', 'ןם', 'ןנ', 'ןן', 'ןס', 'ןע', 'ןפ', 'ןף', 'ןצ', 'ןץ', 'ןק', 'ןר', 'ןש', 'ןת', 'סז', 'סט', 'סצ', 'סץ', 'סש', 'עח', 'עע', 'עף', 'פב', 'פפ', 'ףא', 'ףב', 'ףג', 'ףד', 'ףה', 'ףו', 'ףז', 'ףח', 'ףט', 'ףי', 'ףכ', 'ףך', 'ףל', 'ףמ', 'ףם', 'ףנ', 'ףן', 'ףס', 'ףע', 'ףפ', 'ףף', 'ףצ', 'ףץ', 'ףק', 'ףר', 'ףש', 'ףת', 'צז', 'צס', 'צש', 'ץא', 'ץב', 'ץג', 'ץד', 'ץה', 'ץו', 'ץז', 'ץח', 'ץט', 'ץי', 'ץכ', 'ץך', 'ץל', 'ץמ', 'ץם', 'ץנ', 'ץן', 'ץס', 'ץע', 'ץפ', 'ץף', 'ץצ', 'ץץ', 'ץק', 'ץר', 'ץש', 'ץת', 'קג', 'קז', 'שצ', 'שץ']\n"
     ]
    }
   ],
   "source": [
    "print([pair for pair in allPossiblePairs if pair not in allNgrams])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most common pairs in the Torah?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('את', 5543), ('וי', 4352), ('אל', 4090), ('ים', 3970), ('יה', 3734)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allNgrams.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('טד', 5),\n",
       " ('סס', 5),\n",
       " ('קא', 4),\n",
       " ('כט', 4),\n",
       " ('קף', 4),\n",
       " ('זם', 4),\n",
       " ('חף', 3),\n",
       " ('א\\u200d', 3),\n",
       " ('\\u200dש', 3),\n",
       " ('זך', 3),\n",
       " ('שף', 3),\n",
       " ('עס', 3),\n",
       " ('זח', 3),\n",
       " ('קק', 3),\n",
       " ('אט', 3),\n",
       " ('פמ', 3),\n",
       " ('נץ', 2),\n",
       " ('תץ', 2),\n",
       " ('לץ', 2),\n",
       " ('פף', 2),\n",
       " ('זפ', 2),\n",
       " ('צץ', 2),\n",
       " ('טט', 1),\n",
       " ('אץ', 1),\n",
       " ('סן', 1),\n",
       " ('אא', 1),\n",
       " ('צט', 1),\n",
       " ('קכ', 1),\n",
       " ('הך', 1),\n",
       " ('זג', 1)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Most common:\n",
    "allNgrams.most_common(575)\n",
    "\n",
    "### Least common:\n",
    "allNgrams.most_common(575)[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortedLetters = {k: v for k, v in sorted(allLetters.items(), key=lambda item: item[1])}\n",
    "\n",
    "# plt.hist(list(sortedLetters.keys()), list(sortedLetters.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Todo: make a heatmap of 24x24 letters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get gmatrias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmatrifyAword(word):\n",
    "    \"\"\"\n",
    "    Get the gmatria for one word. Doesn't catch punctuation/errors.\n",
    "\n",
    "    Args:\n",
    "        word (str)\n",
    "\n",
    "    Returns:\n",
    "        The gmatria (int)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return sum([GMATRIA[letter] for letter in word])\n",
    "\n",
    "\n",
    "def calculateGmatriaForAsefer(seferPath):\n",
    "    \"\"\"\n",
    "    Get the gmatria for every word in a text.\n",
    "\n",
    "    Args:\n",
    "        seferPath (str): Path to a file from Sefaria.\n",
    "\n",
    "    \"\"\"\n",
    "#     print (\"Gmatrifying {}...\".format(seferPath))\n",
    "\n",
    "    gmatriasToWords = defaultdict(set)\n",
    "    problematicWords = set()\n",
    "    with open(seferPath, \"r\") as psukim:\n",
    "        \n",
    "        ### Skip first nine lines of file - metadata.\n",
    "        for i in range(9):\n",
    "            next(psukim)\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \").replace(\"\\u200d\", \" \").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    gmatria = gmatrifyAword(word)\n",
    "                    gmatriasToWords[gmatria].add(word)\n",
    "                except KeyError as e:\n",
    "                    print (splitPasuk)\n",
    "                    problematicWords.add(word)\n",
    "#     print (\"Done!\")\n",
    "#     print (\"Had trouble with:\")\n",
    "#     print (problematicWords)\n",
    "    \n",
    "    \n",
    "    return gmatriasToWords\n",
    "\n",
    "    \n",
    "def writeWordsAndTheirGmatria(gmatriasToWords, outputFilePath):\n",
    "    \"\"\"\n",
    "    Write out our results.\n",
    "\n",
    "    Args:\n",
    "        gmatriasToWords (defaultdict(set)): {Gmatria1 (int): {word1withThatGmatria, word2, ...}, ...}\n",
    "        outputFilePath (str): Path to write to.\n",
    "    \"\"\"\n",
    "\n",
    "    writer = csv.writer(open(outputFilePath, \"w\"), delimiter = \"\\t\")\n",
    "    writer.writerow([\"Gmatria\", \"Word\"])\n",
    "    for gmatria, wordsWithThatGmatria in sorted(gmatriasToWords.items()):\n",
    "\n",
    "        writer.writerow([gmatria, \" | \".join(wordsWithThatGmatria)])\n",
    "        \n",
    "    \n",
    "### todo clean this up - either calculating, or reading.\n",
    "def getAllGmatrias():\n",
    "    \n",
    "    gmatriasToWordsForTanach = defaultdict(dict)\n",
    "\n",
    "    tanachPaths = getAllTanachPaths()    \n",
    "\n",
    "    \n",
    "    ### Sections are Torah, Neviyim, Ktuvim\n",
    "    for section, seferPaths in tanachPaths.items():\n",
    "        \n",
    "        gmatriasToWordsForSefer = defaultdict(dict)\n",
    "\n",
    "        \n",
    "        for seferPath in seferPaths:\n",
    "            seferName = seferPath.split(\"/\")[2]\n",
    "            \n",
    "\n",
    "            pathToGmatriaFile = \"Gmatria/{}GmatriaByNumber.tsv\".format(seferName)\n",
    "\n",
    "            if os.path.exists(pathToGmatriaFile):\n",
    "#                 print (\"Gmatria file exists. Reading...\")\n",
    "                reader = csv.reader(open(pathToGmatriaFile), delimiter = \"\\t\")\n",
    "                header = next(reader)\n",
    "                for line in reader:\n",
    "                    line = dict(zip(header, line))\n",
    "                    word = int(line[\"Gmatria\"])\n",
    "                    shifts = set(line[\"Word\"].split(\" | \"))\n",
    "                    gmatriasToWords[word] = shifts\n",
    "#                 print (\"Finished reading.\")\n",
    "            else:\n",
    "#                 print (\"Gmatria file does not exist. Creating...\")\n",
    "                gmatriasToWords = calculateGmatriaForAsefer(seferPath)\n",
    "                writeWordsAndTheirGmatria(gmatriasToWords, outputFilePath = pathToGmatriaFile)\n",
    "\n",
    "\n",
    "            \n",
    "    return gmatriasToWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAllGmatrias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeGematria(gmatriasToWords):\n",
    "    \"\"\"\n",
    "    Analysis.\n",
    "\n",
    "    Args:\n",
    "        gmatriasToWords (defaultdict(set)): {Gmatria1 (int): {word1withThatGmatria, word2, ...}, ...}\n",
    "        originalFilename (str): The text from which the Gmatria dict was made.\n",
    "    \"\"\"\n",
    "\n",
    "    print (\"The largest gmatrias:\")\n",
    "\n",
    "    for gmatria, wordsWithThatGmatria in gmatriasToWords.items():\n",
    "\n",
    "        if len(wordsWithThatGmatria) > 20:\n",
    "\n",
    "            print (\"Gmatria {} has words: {}\".format(gmatria, wordsWithThatGmatria))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gmatria file exists. Reading...\n",
      "Finished reading.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'הארדי', 'וטהר', 'וידר', 'וירד', 'ורוח', 'טהור', 'יבחר', 'צפים', 'רוחו'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmatriasToWords = getAllGmatrias()\n",
    "gmatriasToWords[220]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting file paths...\n",
      "Getting file paths...\n",
      "Getting file paths...\n"
     ]
    }
   ],
   "source": [
    "tanachPaths = getAllTanachPaths()\n",
    "\n",
    "sfarimToWords = {}\n",
    "### Sections are Torah, Neviyim, Ktuvim\n",
    "for section, sectionPaths in tanachPaths.items():\n",
    "    for seferPath in sectionPaths:\n",
    "\n",
    "        seferName = seferPath.split(\"/\")[2]\n",
    "    #     print(seferName)\n",
    "        wordsInSefer = makeWordDictionaryFromSefer(seferPath)\n",
    "        sfarimToWords[seferName] = wordsInSefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write out most common per sefer\n",
    "\n",
    "amountToWrite = 20\n",
    "outputFilePath = \"MostCommonWordsBySefer.tsv\"\n",
    "header = [\"Sefer\"] + [str(i) for i in range(1, amountToWrite + 1)]\n",
    "writer = csv.writer(open(outputFilePath, \"w\"), delimiter = \"\\t\")\n",
    "writer.writerow(header)\n",
    "\n",
    "for sefer, counts in sfarimToWords.items():\n",
    "    \n",
    "    topCounts = counts.most_common(amountToWrite)\n",
    "    topWords = [word for word, count in topCounts]\n",
    "    writer.writerow([sefer] + topWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Get counts per word, across all of Tanach\n",
    "\n",
    "tanachToWords = Counter()\n",
    "\n",
    "for seferName, seferToWords in sfarimToWords.items():\n",
    "        \n",
    "    for word, wordCounts in seferToWords.items():\n",
    "        \n",
    "        tanachToWords[word] += wordCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breishit has 5011 words.\n",
      "Shmot has 4175 words.\n",
      "Dvarim has 4093 words.\n",
      "Vayikra has 2714 words.\n",
      "Bamidbar has 3851 words.\n",
      "Breishit and Shmot share 1486 words.\n",
      "Breishit and Dvarim share 1317 words.\n",
      "Breishit and Vayikra share 864 words.\n",
      "Breishit and Bamidbar share 1327 words.\n",
      "Shmot and Dvarim share 1306 words.\n",
      "Shmot and Vayikra share 1011 words.\n",
      "Shmot and Bamidbar share 1416 words.\n",
      "Dvarim and Vayikra share 862 words.\n",
      "Dvarim and Bamidbar share 1205 words.\n",
      "Vayikra and Bamidbar share 977 words.\n"
     ]
    }
   ],
   "source": [
    "torahSfarim = set([\"Breishit\", \"Shmot\", \"Vayikra\", \"Bamidbar\", \"Dvarim\"])\n",
    "for sefer in torahSfarim:\n",
    "\n",
    "    seferWords = set(sfarimToWords[sefer])\n",
    "    print (\"{} has {} words.\".format(sefer, len(seferWords)))\n",
    "\n",
    "combos = itertools.combinations(torahSfarim, 2)\n",
    "for sefer1, sefer2 in combos:\n",
    "\n",
    "    sefer1words = set(sfarimToWords[sefer1])\n",
    "    sefer2words = set(sfarimToWords[sefer2])\n",
    "\n",
    "    print (\"{} and {} share {} words.\".format(sefer1, sefer2, len(sefer1words.intersection(sefer2words))))\n",
    "#     print (\"{} has {} unique words.\".format(sefer1, len(sefer1words.difference(sefer2words))))\n",
    "#     print (\"{} has {} unique words.\".format(sefer2, len(sefer2words.difference(sefer1words))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 307084 total words in Tanach.\n"
     ]
    }
   ],
   "source": [
    "print (\"There are {} total words in Tanach.\".format(sum(tanachToWords.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenarios for our scoring system:\n",
    "\n",
    "__Starting:__\n",
    "\n",
    "1: aaaab -> ab<br>\n",
    "2: abbb -> ab<br>\n",
    "3: aaaac -> ac\n",
    "\n",
    "totals: a: 9, b: 4, c: 1\n",
    "\n",
    "compare 1 and 3:<br>\n",
    "1/9 * 4 = 16/36\n",
    "\n",
    "compare 1 and 2:<br>\n",
    "1/9 + 1/4 = 13/36\n",
    "\n",
    "compare 2 and 3:<br>\n",
    "1/9 = 4/36\n",
    "\n",
    "\n",
    "compare 1, 2, and 3:<br>\n",
    "1/9 = 4/36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rare words?__\n",
    "\n",
    "a is super common: 2500<br>\n",
    "b is semi common: 500<br>\n",
    "c is rare: 2<br>\n",
    "\n",
    "1: a * 750, b * 249, c * 1<br>\n",
    "2: a* 999, c * 1<br>\n",
    "3: a * 750, b * 250\n",
    "\n",
    "\n",
    "compare 1 and 2:<br>\n",
    "750/2500 + 1/2\n",
    "\n",
    "compare 1 and 3:<br>\n",
    "750/2500, 250/500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem with larger sfarim?__\n",
    "\n",
    "1: 5000 as, 1 c<br>\n",
    "2: 1a, 1b, 1c<br>\n",
    "3: 1b, 1c<br>\n",
    "4: 2500 as, 2500 bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This counts each word once.\n",
    "\n",
    "def compareSfarimNaive(listOfSfarim):\n",
    "    \n",
    "    unionWords = set()\n",
    "    intersectionWords = set(sfarimToWords[listOfSfarim[0]])\n",
    "    \n",
    "    for sefer in listOfSfarim:\n",
    "        \n",
    "        seferWords = set(sfarimToWords[sefer])\n",
    "        \n",
    "        unionWords |= seferWords\n",
    "        intersectionWords &= seferWords\n",
    "        \n",
    "    total = len(unionWords)\n",
    "    shared = len(intersectionWords)\n",
    "    sharedPercentage = float(shared) / total * 100\n",
    "    print (\"There are {} unique words across the {} sfarim.\".format(total, len(listOfSfarim)))\n",
    "    print (\"They share {} of them ({:.2f} percent).\".format(shared, sharedPercentage))\n",
    "    \n",
    "    ### Weighted shared percentage:\n",
    "    \n",
    "    individualSharedPercentages = {}\n",
    "    \n",
    "    for sefer in listOfSfarim:\n",
    "        \n",
    "        seferWords = set(sfarimToWords[sefer])\n",
    "        sefersSharedWordsWithAllOtherSfarim = seferWords.intersection(intersectionWords)\n",
    "        \n",
    "        sefersSharedPercentage = float(len(sefersSharedWordsWithAllOtherSfarim)) / len(seferWords)\n",
    "        \n",
    "        individualSharedPercentages[sefer] = sefersSharedPercentage\n",
    "    \n",
    "    meanSharedPercentage = 100 * sum(individualSharedPercentages.values())/len(individualSharedPercentages)\n",
    "    print (\"The average shared percentage is {:.2f}.\".format(meanSharedPercentage))\n",
    "    \n",
    "    for sefer in listOfSfarim:\n",
    "        \n",
    "        print (\"{}: {:.2f}\".format(sefer, 100*individualSharedPercentages[sefer]))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This uses the Alex Joe weighting system (ie tf=idf?)\n",
    "\n",
    "def compareSfarimScoring(listOfSfarim):\n",
    "    \n",
    "    unionWords = set()\n",
    "    intersectionWords = set(sfarimToWords[listOfSfarim[0]])\n",
    "\n",
    "    for sefer in listOfSfarim:\n",
    "        \n",
    "        seferWords = set(sfarimToWords[sefer])\n",
    "        \n",
    "        unionWords |= seferWords\n",
    "        intersectionWords &= seferWords\n",
    "        \n",
    "    ### Calculate score:\n",
    "    score = 0\n",
    "    for word in intersectionWords:\n",
    "        \n",
    "        tanachOccurences = float(tanachToWords[word])\n",
    "        \n",
    "        amountShared = min([sfarimToWords[sefer][word] for sefer in listOfSfarim])\n",
    "        \n",
    "        score += amountShared/tanachOccurences\n",
    "        \n",
    "\n",
    "    ### Normalize:\n",
    "    \n",
    "    ## Divide by the total words across all the sfarim, to penalize larger sfarim.\n",
    "    totalWords = len(unionWords)\n",
    "    \n",
    "    \n",
    "    ### Multiply by number of sfarim so that the perfect score can be 1.\n",
    "    numberOfSfarim = len(listOfSfarim)\n",
    "    score = score * numberOfSfarim / totalWords\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194.25800421917864"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[(\"Bamidbar\", \"Dvarim\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02882593919263669"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compareSfarimScoring([\"Bamidbar\", \"Dvarim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### todo: \n",
    "### change weighting to not favor bigger sefers. divide by the union\n",
    "    ### to check that we've removed that bias, plot average score per sefer, versus its size, to make sure\n",
    "    ### not correlated.\n",
    "### all pairwise comparisons\n",
    "### pinwheel visualization - pick the sfarim you want, shows score in middle\n",
    "### Change weightings to bring in ngrams: right now we've done 1-word comparisons. add in \n",
    "### weightings of n-grams of 2, then n-grams of 3.\n",
    "### Is this just a plagiarism detector? Let's code next time and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vayikra Shmot\n",
      "Vayikra Breishit\n",
      "Vayikra Bamidbar\n",
      "Vayikra Dvarim\n",
      "Vayikra I Samuel\n",
      "Vayikra Zephaniah\n",
      "Vayikra Haggai\n",
      "Vayikra Jeremiah\n",
      "Vayikra Joel\n",
      "Vayikra I Kings\n",
      "Vayikra Amos\n",
      "Vayikra Judges\n",
      "Vayikra Jonah\n",
      "Vayikra Ezekiel\n",
      "Vayikra Nahum\n",
      "Vayikra II Samuel\n",
      "Vayikra Habakkuk\n",
      "Vayikra Micah\n",
      "Vayikra Obadiah\n",
      "Vayikra Hosea\n",
      "Vayikra II Kings\n",
      "Vayikra Isaiah\n",
      "Vayikra Malachi\n",
      "Vayikra Joshua\n",
      "Vayikra Zechariah\n",
      "Vayikra Ecclesiastes\n",
      "Vayikra Ezra\n",
      "Vayikra Ruth\n",
      "Vayikra II Chronicles\n",
      "Vayikra Daniel\n",
      "Vayikra Proverbs\n",
      "Vayikra Lamentations\n",
      "Vayikra Nehemiah\n",
      "Vayikra Job\n",
      "Vayikra Psalms\n",
      "Vayikra Song of Songs\n",
      "Vayikra I Chronicles\n",
      "Vayikra Esther\n",
      "Shmot Breishit\n",
      "Shmot Bamidbar\n",
      "Shmot Dvarim\n",
      "Shmot I Samuel\n",
      "Shmot Zephaniah\n",
      "Shmot Haggai\n",
      "Shmot Jeremiah\n",
      "Shmot Joel\n",
      "Shmot I Kings\n",
      "Shmot Amos\n",
      "Shmot Judges\n",
      "Shmot Jonah\n",
      "Shmot Ezekiel\n",
      "Shmot Nahum\n",
      "Shmot II Samuel\n",
      "Shmot Habakkuk\n",
      "Shmot Micah\n",
      "Shmot Obadiah\n",
      "Shmot Hosea\n",
      "Shmot II Kings\n",
      "Shmot Isaiah\n",
      "Shmot Malachi\n",
      "Shmot Joshua\n",
      "Shmot Zechariah\n",
      "Shmot Ecclesiastes\n",
      "Shmot Ezra\n",
      "Shmot Ruth\n",
      "Shmot II Chronicles\n",
      "Shmot Daniel\n",
      "Shmot Proverbs\n",
      "Shmot Lamentations\n",
      "Shmot Nehemiah\n",
      "Shmot Job\n",
      "Shmot Psalms\n",
      "Shmot Song of Songs\n",
      "Shmot I Chronicles\n",
      "Shmot Esther\n",
      "Breishit Bamidbar\n",
      "Breishit Dvarim\n",
      "Breishit I Samuel\n",
      "Breishit Zephaniah\n",
      "Breishit Haggai\n",
      "Breishit Jeremiah\n",
      "Breishit Joel\n",
      "Breishit I Kings\n",
      "Breishit Amos\n",
      "Breishit Judges\n",
      "Breishit Jonah\n",
      "Breishit Ezekiel\n",
      "Breishit Nahum\n",
      "Breishit II Samuel\n",
      "Breishit Habakkuk\n",
      "Breishit Micah\n",
      "Breishit Obadiah\n",
      "Breishit Hosea\n",
      "Breishit II Kings\n",
      "Breishit Isaiah\n",
      "Breishit Malachi\n",
      "Breishit Joshua\n",
      "Breishit Zechariah\n",
      "Breishit Ecclesiastes\n",
      "Breishit Ezra\n",
      "Breishit Ruth\n",
      "Breishit II Chronicles\n",
      "Breishit Daniel\n",
      "Breishit Proverbs\n",
      "Breishit Lamentations\n",
      "Breishit Nehemiah\n",
      "Breishit Job\n",
      "Breishit Psalms\n",
      "Breishit Song of Songs\n",
      "Breishit I Chronicles\n",
      "Breishit Esther\n",
      "Bamidbar Dvarim\n",
      "Bamidbar I Samuel\n",
      "Bamidbar Zephaniah\n",
      "Bamidbar Haggai\n",
      "Bamidbar Jeremiah\n",
      "Bamidbar Joel\n",
      "Bamidbar I Kings\n",
      "Bamidbar Amos\n",
      "Bamidbar Judges\n",
      "Bamidbar Jonah\n",
      "Bamidbar Ezekiel\n",
      "Bamidbar Nahum\n",
      "Bamidbar II Samuel\n",
      "Bamidbar Habakkuk\n",
      "Bamidbar Micah\n",
      "Bamidbar Obadiah\n",
      "Bamidbar Hosea\n",
      "Bamidbar II Kings\n",
      "Bamidbar Isaiah\n",
      "Bamidbar Malachi\n",
      "Bamidbar Joshua\n",
      "Bamidbar Zechariah\n",
      "Bamidbar Ecclesiastes\n",
      "Bamidbar Ezra\n",
      "Bamidbar Ruth\n",
      "Bamidbar II Chronicles\n",
      "Bamidbar Daniel\n",
      "Bamidbar Proverbs\n",
      "Bamidbar Lamentations\n",
      "Bamidbar Nehemiah\n",
      "Bamidbar Job\n",
      "Bamidbar Psalms\n",
      "Bamidbar Song of Songs\n",
      "Bamidbar I Chronicles\n",
      "Bamidbar Esther\n",
      "Dvarim I Samuel\n",
      "Dvarim Zephaniah\n",
      "Dvarim Haggai\n",
      "Dvarim Jeremiah\n",
      "Dvarim Joel\n",
      "Dvarim I Kings\n",
      "Dvarim Amos\n",
      "Dvarim Judges\n",
      "Dvarim Jonah\n",
      "Dvarim Ezekiel\n",
      "Dvarim Nahum\n",
      "Dvarim II Samuel\n",
      "Dvarim Habakkuk\n",
      "Dvarim Micah\n",
      "Dvarim Obadiah\n",
      "Dvarim Hosea\n",
      "Dvarim II Kings\n",
      "Dvarim Isaiah\n",
      "Dvarim Malachi\n",
      "Dvarim Joshua\n",
      "Dvarim Zechariah\n",
      "Dvarim Ecclesiastes\n",
      "Dvarim Ezra\n",
      "Dvarim Ruth\n",
      "Dvarim II Chronicles\n",
      "Dvarim Daniel\n",
      "Dvarim Proverbs\n",
      "Dvarim Lamentations\n",
      "Dvarim Nehemiah\n",
      "Dvarim Job\n",
      "Dvarim Psalms\n",
      "Dvarim Song of Songs\n",
      "Dvarim I Chronicles\n",
      "Dvarim Esther\n",
      "I Samuel Zephaniah\n",
      "I Samuel Haggai\n",
      "I Samuel Jeremiah\n",
      "I Samuel Joel\n",
      "I Samuel I Kings\n",
      "I Samuel Amos\n",
      "I Samuel Judges\n",
      "I Samuel Jonah\n",
      "I Samuel Ezekiel\n",
      "I Samuel Nahum\n",
      "I Samuel II Samuel\n",
      "I Samuel Habakkuk\n",
      "I Samuel Micah\n",
      "I Samuel Obadiah\n",
      "I Samuel Hosea\n",
      "I Samuel II Kings\n",
      "I Samuel Isaiah\n",
      "I Samuel Malachi\n",
      "I Samuel Joshua\n",
      "I Samuel Zechariah\n",
      "I Samuel Ecclesiastes\n",
      "I Samuel Ezra\n",
      "I Samuel Ruth\n",
      "I Samuel II Chronicles\n",
      "I Samuel Daniel\n",
      "I Samuel Proverbs\n",
      "I Samuel Lamentations\n",
      "I Samuel Nehemiah\n",
      "I Samuel Job\n",
      "I Samuel Psalms\n",
      "I Samuel Song of Songs\n",
      "I Samuel I Chronicles\n",
      "I Samuel Esther\n",
      "Zephaniah Haggai\n",
      "Zephaniah Jeremiah\n",
      "Zephaniah Joel\n",
      "Zephaniah I Kings\n",
      "Zephaniah Amos\n",
      "Zephaniah Judges\n",
      "Zephaniah Jonah\n",
      "Zephaniah Ezekiel\n",
      "Zephaniah Nahum\n",
      "Zephaniah II Samuel\n",
      "Zephaniah Habakkuk\n",
      "Zephaniah Micah\n",
      "Zephaniah Obadiah\n",
      "Zephaniah Hosea\n",
      "Zephaniah II Kings\n",
      "Zephaniah Isaiah\n",
      "Zephaniah Malachi\n",
      "Zephaniah Joshua\n",
      "Zephaniah Zechariah\n",
      "Zephaniah Ecclesiastes\n",
      "Zephaniah Ezra\n",
      "Zephaniah Ruth\n",
      "Zephaniah II Chronicles\n",
      "Zephaniah Daniel\n",
      "Zephaniah Proverbs\n",
      "Zephaniah Lamentations\n",
      "Zephaniah Nehemiah\n",
      "Zephaniah Job\n",
      "Zephaniah Psalms\n",
      "Zephaniah Song of Songs\n",
      "Zephaniah I Chronicles\n",
      "Zephaniah Esther\n",
      "Haggai Jeremiah\n",
      "Haggai Joel\n",
      "Haggai I Kings\n",
      "Haggai Amos\n",
      "Haggai Judges\n",
      "Haggai Jonah\n",
      "Haggai Ezekiel\n",
      "Haggai Nahum\n",
      "Haggai II Samuel\n",
      "Haggai Habakkuk\n",
      "Haggai Micah\n",
      "Haggai Obadiah\n",
      "Haggai Hosea\n",
      "Haggai II Kings\n",
      "Haggai Isaiah\n",
      "Haggai Malachi\n",
      "Haggai Joshua\n",
      "Haggai Zechariah\n",
      "Haggai Ecclesiastes\n",
      "Haggai Ezra\n",
      "Haggai Ruth\n",
      "Haggai II Chronicles\n",
      "Haggai Daniel\n",
      "Haggai Proverbs\n",
      "Haggai Lamentations\n",
      "Haggai Nehemiah\n",
      "Haggai Job\n",
      "Haggai Psalms\n",
      "Haggai Song of Songs\n",
      "Haggai I Chronicles\n",
      "Haggai Esther\n",
      "Jeremiah Joel\n",
      "Jeremiah I Kings\n",
      "Jeremiah Amos\n",
      "Jeremiah Judges\n",
      "Jeremiah Jonah\n",
      "Jeremiah Ezekiel\n",
      "Jeremiah Nahum\n",
      "Jeremiah II Samuel\n",
      "Jeremiah Habakkuk\n",
      "Jeremiah Micah\n",
      "Jeremiah Obadiah\n",
      "Jeremiah Hosea\n",
      "Jeremiah II Kings\n",
      "Jeremiah Isaiah\n",
      "Jeremiah Malachi\n",
      "Jeremiah Joshua\n",
      "Jeremiah Zechariah\n",
      "Jeremiah Ecclesiastes\n",
      "Jeremiah Ezra\n",
      "Jeremiah Ruth\n",
      "Jeremiah II Chronicles\n",
      "Jeremiah Daniel\n",
      "Jeremiah Proverbs\n",
      "Jeremiah Lamentations\n",
      "Jeremiah Nehemiah\n",
      "Jeremiah Job\n",
      "Jeremiah Psalms\n",
      "Jeremiah Song of Songs\n",
      "Jeremiah I Chronicles\n",
      "Jeremiah Esther\n",
      "Joel I Kings\n",
      "Joel Amos\n",
      "Joel Judges\n",
      "Joel Jonah\n",
      "Joel Ezekiel\n",
      "Joel Nahum\n",
      "Joel II Samuel\n",
      "Joel Habakkuk\n",
      "Joel Micah\n",
      "Joel Obadiah\n",
      "Joel Hosea\n",
      "Joel II Kings\n",
      "Joel Isaiah\n",
      "Joel Malachi\n",
      "Joel Joshua\n",
      "Joel Zechariah\n",
      "Joel Ecclesiastes\n",
      "Joel Ezra\n",
      "Joel Ruth\n",
      "Joel II Chronicles\n",
      "Joel Daniel\n",
      "Joel Proverbs\n",
      "Joel Lamentations\n",
      "Joel Nehemiah\n",
      "Joel Job\n",
      "Joel Psalms\n",
      "Joel Song of Songs\n",
      "Joel I Chronicles\n",
      "Joel Esther\n",
      "I Kings Amos\n",
      "I Kings Judges\n",
      "I Kings Jonah\n",
      "I Kings Ezekiel\n",
      "I Kings Nahum\n",
      "I Kings II Samuel\n",
      "I Kings Habakkuk\n",
      "I Kings Micah\n",
      "I Kings Obadiah\n",
      "I Kings Hosea\n",
      "I Kings II Kings\n",
      "I Kings Isaiah\n",
      "I Kings Malachi\n",
      "I Kings Joshua\n",
      "I Kings Zechariah\n",
      "I Kings Ecclesiastes\n",
      "I Kings Ezra\n",
      "I Kings Ruth\n",
      "I Kings II Chronicles\n",
      "I Kings Daniel\n",
      "I Kings Proverbs\n",
      "I Kings Lamentations\n",
      "I Kings Nehemiah\n",
      "I Kings Job\n",
      "I Kings Psalms\n",
      "I Kings Song of Songs\n",
      "I Kings I Chronicles\n",
      "I Kings Esther\n",
      "Amos Judges\n",
      "Amos Jonah\n",
      "Amos Ezekiel\n",
      "Amos Nahum\n",
      "Amos II Samuel\n",
      "Amos Habakkuk\n",
      "Amos Micah\n",
      "Amos Obadiah\n",
      "Amos Hosea\n",
      "Amos II Kings\n",
      "Amos Isaiah\n",
      "Amos Malachi\n",
      "Amos Joshua\n",
      "Amos Zechariah\n",
      "Amos Ecclesiastes\n",
      "Amos Ezra\n",
      "Amos Ruth\n",
      "Amos II Chronicles\n",
      "Amos Daniel\n",
      "Amos Proverbs\n",
      "Amos Lamentations\n",
      "Amos Nehemiah\n",
      "Amos Job\n",
      "Amos Psalms\n",
      "Amos Song of Songs\n",
      "Amos I Chronicles\n",
      "Amos Esther\n",
      "Judges Jonah\n",
      "Judges Ezekiel\n",
      "Judges Nahum\n",
      "Judges II Samuel\n",
      "Judges Habakkuk\n",
      "Judges Micah\n",
      "Judges Obadiah\n",
      "Judges Hosea\n",
      "Judges II Kings\n",
      "Judges Isaiah\n",
      "Judges Malachi\n",
      "Judges Joshua\n",
      "Judges Zechariah\n",
      "Judges Ecclesiastes\n",
      "Judges Ezra\n",
      "Judges Ruth\n",
      "Judges II Chronicles\n",
      "Judges Daniel\n",
      "Judges Proverbs\n",
      "Judges Lamentations\n",
      "Judges Nehemiah\n",
      "Judges Job\n",
      "Judges Psalms\n",
      "Judges Song of Songs\n",
      "Judges I Chronicles\n",
      "Judges Esther\n",
      "Jonah Ezekiel\n",
      "Jonah Nahum\n",
      "Jonah II Samuel\n",
      "Jonah Habakkuk\n",
      "Jonah Micah\n",
      "Jonah Obadiah\n",
      "Jonah Hosea\n",
      "Jonah II Kings\n",
      "Jonah Isaiah\n",
      "Jonah Malachi\n",
      "Jonah Joshua\n",
      "Jonah Zechariah\n",
      "Jonah Ecclesiastes\n",
      "Jonah Ezra\n",
      "Jonah Ruth\n",
      "Jonah II Chronicles\n",
      "Jonah Daniel\n",
      "Jonah Proverbs\n",
      "Jonah Lamentations\n",
      "Jonah Nehemiah\n",
      "Jonah Job\n",
      "Jonah Psalms\n",
      "Jonah Song of Songs\n",
      "Jonah I Chronicles\n",
      "Jonah Esther\n",
      "Ezekiel Nahum\n",
      "Ezekiel II Samuel\n",
      "Ezekiel Habakkuk\n",
      "Ezekiel Micah\n",
      "Ezekiel Obadiah\n",
      "Ezekiel Hosea\n",
      "Ezekiel II Kings\n",
      "Ezekiel Isaiah\n",
      "Ezekiel Malachi\n",
      "Ezekiel Joshua\n",
      "Ezekiel Zechariah\n",
      "Ezekiel Ecclesiastes\n",
      "Ezekiel Ezra\n",
      "Ezekiel Ruth\n",
      "Ezekiel II Chronicles\n",
      "Ezekiel Daniel\n",
      "Ezekiel Proverbs\n",
      "Ezekiel Lamentations\n",
      "Ezekiel Nehemiah\n",
      "Ezekiel Job\n",
      "Ezekiel Psalms\n",
      "Ezekiel Song of Songs\n",
      "Ezekiel I Chronicles\n",
      "Ezekiel Esther\n",
      "Nahum II Samuel\n",
      "Nahum Habakkuk\n",
      "Nahum Micah\n",
      "Nahum Obadiah\n",
      "Nahum Hosea\n",
      "Nahum II Kings\n",
      "Nahum Isaiah\n",
      "Nahum Malachi\n",
      "Nahum Joshua\n",
      "Nahum Zechariah\n",
      "Nahum Ecclesiastes\n",
      "Nahum Ezra\n",
      "Nahum Ruth\n",
      "Nahum II Chronicles\n",
      "Nahum Daniel\n",
      "Nahum Proverbs\n",
      "Nahum Lamentations\n",
      "Nahum Nehemiah\n",
      "Nahum Job\n",
      "Nahum Psalms\n",
      "Nahum Song of Songs\n",
      "Nahum I Chronicles\n",
      "Nahum Esther\n",
      "II Samuel Habakkuk\n",
      "II Samuel Micah\n",
      "II Samuel Obadiah\n",
      "II Samuel Hosea\n",
      "II Samuel II Kings\n",
      "II Samuel Isaiah\n",
      "II Samuel Malachi\n",
      "II Samuel Joshua\n",
      "II Samuel Zechariah\n",
      "II Samuel Ecclesiastes\n",
      "II Samuel Ezra\n",
      "II Samuel Ruth\n",
      "II Samuel II Chronicles\n",
      "II Samuel Daniel\n",
      "II Samuel Proverbs\n",
      "II Samuel Lamentations\n",
      "II Samuel Nehemiah\n",
      "II Samuel Job\n",
      "II Samuel Psalms\n",
      "II Samuel Song of Songs\n",
      "II Samuel I Chronicles\n",
      "II Samuel Esther\n",
      "Habakkuk Micah\n",
      "Habakkuk Obadiah\n",
      "Habakkuk Hosea\n",
      "Habakkuk II Kings\n",
      "Habakkuk Isaiah\n",
      "Habakkuk Malachi\n",
      "Habakkuk Joshua\n",
      "Habakkuk Zechariah\n",
      "Habakkuk Ecclesiastes\n",
      "Habakkuk Ezra\n",
      "Habakkuk Ruth\n",
      "Habakkuk II Chronicles\n",
      "Habakkuk Daniel\n",
      "Habakkuk Proverbs\n",
      "Habakkuk Lamentations\n",
      "Habakkuk Nehemiah\n",
      "Habakkuk Job\n",
      "Habakkuk Psalms\n",
      "Habakkuk Song of Songs\n",
      "Habakkuk I Chronicles\n",
      "Habakkuk Esther\n",
      "Micah Obadiah\n",
      "Micah Hosea\n",
      "Micah II Kings\n",
      "Micah Isaiah\n",
      "Micah Malachi\n",
      "Micah Joshua\n",
      "Micah Zechariah\n",
      "Micah Ecclesiastes\n",
      "Micah Ezra\n",
      "Micah Ruth\n",
      "Micah II Chronicles\n",
      "Micah Daniel\n",
      "Micah Proverbs\n",
      "Micah Lamentations\n",
      "Micah Nehemiah\n",
      "Micah Job\n",
      "Micah Psalms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micah Song of Songs\n",
      "Micah I Chronicles\n",
      "Micah Esther\n",
      "Obadiah Hosea\n",
      "Obadiah II Kings\n",
      "Obadiah Isaiah\n",
      "Obadiah Malachi\n",
      "Obadiah Joshua\n",
      "Obadiah Zechariah\n",
      "Obadiah Ecclesiastes\n",
      "Obadiah Ezra\n",
      "Obadiah Ruth\n",
      "Obadiah II Chronicles\n",
      "Obadiah Daniel\n",
      "Obadiah Proverbs\n",
      "Obadiah Lamentations\n",
      "Obadiah Nehemiah\n",
      "Obadiah Job\n",
      "Obadiah Psalms\n",
      "Obadiah Song of Songs\n",
      "Obadiah I Chronicles\n",
      "Obadiah Esther\n",
      "Hosea II Kings\n",
      "Hosea Isaiah\n",
      "Hosea Malachi\n",
      "Hosea Joshua\n",
      "Hosea Zechariah\n",
      "Hosea Ecclesiastes\n",
      "Hosea Ezra\n",
      "Hosea Ruth\n",
      "Hosea II Chronicles\n",
      "Hosea Daniel\n",
      "Hosea Proverbs\n",
      "Hosea Lamentations\n",
      "Hosea Nehemiah\n",
      "Hosea Job\n",
      "Hosea Psalms\n",
      "Hosea Song of Songs\n",
      "Hosea I Chronicles\n",
      "Hosea Esther\n",
      "II Kings Isaiah\n",
      "II Kings Malachi\n",
      "II Kings Joshua\n",
      "II Kings Zechariah\n",
      "II Kings Ecclesiastes\n",
      "II Kings Ezra\n",
      "II Kings Ruth\n",
      "II Kings II Chronicles\n",
      "II Kings Daniel\n",
      "II Kings Proverbs\n",
      "II Kings Lamentations\n",
      "II Kings Nehemiah\n",
      "II Kings Job\n",
      "II Kings Psalms\n",
      "II Kings Song of Songs\n",
      "II Kings I Chronicles\n",
      "II Kings Esther\n",
      "Isaiah Malachi\n",
      "Isaiah Joshua\n",
      "Isaiah Zechariah\n",
      "Isaiah Ecclesiastes\n",
      "Isaiah Ezra\n",
      "Isaiah Ruth\n",
      "Isaiah II Chronicles\n",
      "Isaiah Daniel\n",
      "Isaiah Proverbs\n",
      "Isaiah Lamentations\n",
      "Isaiah Nehemiah\n",
      "Isaiah Job\n",
      "Isaiah Psalms\n",
      "Isaiah Song of Songs\n",
      "Isaiah I Chronicles\n",
      "Isaiah Esther\n",
      "Malachi Joshua\n",
      "Malachi Zechariah\n",
      "Malachi Ecclesiastes\n",
      "Malachi Ezra\n",
      "Malachi Ruth\n",
      "Malachi II Chronicles\n",
      "Malachi Daniel\n",
      "Malachi Proverbs\n",
      "Malachi Lamentations\n",
      "Malachi Nehemiah\n",
      "Malachi Job\n",
      "Malachi Psalms\n",
      "Malachi Song of Songs\n",
      "Malachi I Chronicles\n",
      "Malachi Esther\n",
      "Joshua Zechariah\n",
      "Joshua Ecclesiastes\n",
      "Joshua Ezra\n",
      "Joshua Ruth\n",
      "Joshua II Chronicles\n",
      "Joshua Daniel\n",
      "Joshua Proverbs\n",
      "Joshua Lamentations\n",
      "Joshua Nehemiah\n",
      "Joshua Job\n",
      "Joshua Psalms\n",
      "Joshua Song of Songs\n",
      "Joshua I Chronicles\n",
      "Joshua Esther\n",
      "Zechariah Ecclesiastes\n",
      "Zechariah Ezra\n",
      "Zechariah Ruth\n",
      "Zechariah II Chronicles\n",
      "Zechariah Daniel\n",
      "Zechariah Proverbs\n",
      "Zechariah Lamentations\n",
      "Zechariah Nehemiah\n",
      "Zechariah Job\n",
      "Zechariah Psalms\n",
      "Zechariah Song of Songs\n",
      "Zechariah I Chronicles\n",
      "Zechariah Esther\n",
      "Ecclesiastes Ezra\n",
      "Ecclesiastes Ruth\n",
      "Ecclesiastes II Chronicles\n",
      "Ecclesiastes Daniel\n",
      "Ecclesiastes Proverbs\n",
      "Ecclesiastes Lamentations\n",
      "Ecclesiastes Nehemiah\n",
      "Ecclesiastes Job\n",
      "Ecclesiastes Psalms\n",
      "Ecclesiastes Song of Songs\n",
      "Ecclesiastes I Chronicles\n",
      "Ecclesiastes Esther\n",
      "Ezra Ruth\n",
      "Ezra II Chronicles\n",
      "Ezra Daniel\n",
      "Ezra Proverbs\n",
      "Ezra Lamentations\n",
      "Ezra Nehemiah\n",
      "Ezra Job\n",
      "Ezra Psalms\n",
      "Ezra Song of Songs\n",
      "Ezra I Chronicles\n",
      "Ezra Esther\n",
      "Ruth II Chronicles\n",
      "Ruth Daniel\n",
      "Ruth Proverbs\n",
      "Ruth Lamentations\n",
      "Ruth Nehemiah\n",
      "Ruth Job\n",
      "Ruth Psalms\n",
      "Ruth Song of Songs\n",
      "Ruth I Chronicles\n",
      "Ruth Esther\n",
      "II Chronicles Daniel\n",
      "II Chronicles Proverbs\n",
      "II Chronicles Lamentations\n",
      "II Chronicles Nehemiah\n",
      "II Chronicles Job\n",
      "II Chronicles Psalms\n",
      "II Chronicles Song of Songs\n",
      "II Chronicles I Chronicles\n",
      "II Chronicles Esther\n",
      "Daniel Proverbs\n",
      "Daniel Lamentations\n",
      "Daniel Nehemiah\n",
      "Daniel Job\n",
      "Daniel Psalms\n",
      "Daniel Song of Songs\n",
      "Daniel I Chronicles\n",
      "Daniel Esther\n",
      "Proverbs Lamentations\n",
      "Proverbs Nehemiah\n",
      "Proverbs Job\n",
      "Proverbs Psalms\n",
      "Proverbs Song of Songs\n",
      "Proverbs I Chronicles\n",
      "Proverbs Esther\n",
      "Lamentations Nehemiah\n",
      "Lamentations Job\n",
      "Lamentations Psalms\n",
      "Lamentations Song of Songs\n",
      "Lamentations I Chronicles\n",
      "Lamentations Esther\n",
      "Nehemiah Job\n",
      "Nehemiah Psalms\n",
      "Nehemiah Song of Songs\n",
      "Nehemiah I Chronicles\n",
      "Nehemiah Esther\n",
      "Job Psalms\n",
      "Job Song of Songs\n",
      "Job I Chronicles\n",
      "Job Esther\n",
      "Psalms Song of Songs\n",
      "Psalms I Chronicles\n",
      "Psalms Esther\n",
      "Song of Songs I Chronicles\n",
      "Song of Songs Esther\n",
      "I Chronicles Esther\n"
     ]
    }
   ],
   "source": [
    "### All comparisons\n",
    "sfarimNames = sfarimToWords.keys()\n",
    "combos = itertools.combinations(sfarimNames, 2)\n",
    "scores = defaultdict(dict)\n",
    "for sefer1, sefer2 in combos:\n",
    "    \n",
    "    print (sefer1, sefer2)\n",
    "    score = compareSfarimScoring([sefer1, sefer2])\n",
    "    \n",
    "    scores[(sefer1, sefer2)] = score\n",
    "    scores[(sefer2, sefer1)] = score  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFileName = \"sfarimComparisons.tsv\"\n",
    "with open(outputFileName, \"w\") as out:\n",
    "    \n",
    "    out.write(\"Sefer1\\tSefer2\\tScore\\n\")\n",
    "    skipDuplicate = True ### Because we did symmetrical tuples)\n",
    "    for (sefer1, sefer2), score in sorted(scores.items(), key = lambda sefer: sefer[1], reverse = True):\n",
    "        \n",
    "        if skipDuplicate:\n",
    "            \n",
    "            out.write(\"{}\\t{}\\t{}\\n\".format(sefer1, sefer2, score))\n",
    "        skipDuplicate = not skipDuplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motzaot HaPeh\n",
    "מוצאות הפה\n",
    "\n",
    "The 5 Organs of Articulation.\n",
    "\n",
    "Tnuyot Haotiyot\n",
    "תנועות האותיות\n",
    "\n",
    "(From [here](https://www.inner.org/gematria/5origins.php).)\n",
    "\n",
    "Todo: vowels/non-matres lectiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the motzaot categories\n",
    "motzaotToLetters = {}\n",
    "motzaotToLetters[\"throat\"] = {\"א\",\"ח\", \"ה\", \"ע\"}\n",
    "motzaotToLetters[\"palate\"] = {\"כ\",\"י\", \"ג\", \"ק\", \"ך\"}\n",
    "motzaotToLetters[\"tongue\"] = {\"ר\" ,\"ס\", \"ש\", \"ז\", \"צ\", \"ץ\"}\n",
    "motzaotToLetters[\"teeth\"] = {\"נ\" ,\"ל\", \"ט\", \"ד\", \"ת\", \"ן\"}\n",
    "motzaotToLetters[\"lips\"] = {\"פ\" ,\"מ\", \"ו\", \"ב\", \"ם\", \"ף\"}\n",
    "\n",
    "lettersToMotzaot = {}\n",
    "for organ, letters in motzaotToLetters.items():\n",
    "    \n",
    "    for letter in letters:\n",
    "        lettersToMotzaot[letter] = organ\n",
    "        \n",
    "# motzaotToKey = {\"throat\": \"t\", \"palate\": \"p\", \"tongue\": \"g\", \"teeth\": \"e\", \"lips\": \"l\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertWordToMotzaot(word):\n",
    "    \n",
    "#     convertedWord = [motzaotToKey[lettersToMotzaot[letter]] for letter in word]\n",
    "    convertedWord = [lettersToMotzaot[letter] for letter in word]\n",
    "    ### Change from list to string:\n",
    "    convertedWord = \"\".join(convertedWord)\n",
    "    return convertedWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDictionariesFromSefer(filename, allWords, allLetters):\n",
    "    \n",
    "    problematicWords = set()\n",
    "    \n",
    "    with open(filename, \"r\") as psukim:\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    ### Change to motzaot:\n",
    "                    convertedWord = convertWordToMotzaot(word)\n",
    "                    allWords[convertedWord] += 1\n",
    "                    \n",
    "                    for letter in convertedWord.split(\"_\"):\n",
    "                        allLetters[letter] += 1                    \n",
    "                except KeyError as e:\n",
    "                    problematicWords.add(word)\n",
    "    return allWords, allLetters\n",
    "\n",
    "\n",
    "def makeNgramsDictionaryFromSefer(filename, allNgrams, sizeOfngram):\n",
    "    \n",
    "    problematicWords = set()\n",
    "    \n",
    "    with open(filename, \"r\") as psukim:\n",
    "        for pasuk in psukim:\n",
    "\n",
    "            cleanedPasuk = pasuk.strip().replace(\"־\", \" \").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            splitPasuk = cleanedPasuk.split(\" \")\n",
    "\n",
    "            # Skip the non-text lines.\n",
    "            if len(splitPasuk) == 1 or splitPasuk[0] == \"Chapter\":\n",
    "                continue\n",
    "\n",
    "            for word in splitPasuk:\n",
    "                try:\n",
    "                    \n",
    "                    convertedWord = convertWordToMotzaot(word).split(\"_\")\n",
    "                    \n",
    "                    for letterIndex in range(len(convertedWord) - sizeOfngram + 1):\n",
    "                        \n",
    "    \n",
    "                        ngram = \"_\".join(convertedWord[letterIndex:letterIndex + sizeOfngram])\n",
    "                        allNgrams[ngram] += 1\n",
    "                except KeyError as e:\n",
    "                    problematicWords.add(word)\n",
    "    return allNgrams  \n",
    "\n",
    "def runOnWholeTorah(seferFilenames):\n",
    "    \n",
    "    allWords = Counter()\n",
    "    allLetters = Counter()\n",
    "    allNgrams = Counter()\n",
    "    \n",
    "    for seferFilename in seferFilenames:\n",
    "        \n",
    "        seferName = seferFilename.replace(\".txt\", \"\").split(\"/\")[-1]\n",
    "        print(seferName)\n",
    "        allWords, allLetters = makeDictionariesFromSefer(seferFilename, allWords, allLetters)\n",
    "        allNgrams = makeNgramsDictionaryFromSefer(seferFilename, allNgrams, sizeOfngram = 3)\n",
    "\n",
    "    return allWords, allLetters, allNgrams\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting filenames...\n",
      "vayikra\n",
      "dvarim\n",
      "breishit\n",
      "shmot\n",
      "bamidbar\n"
     ]
    }
   ],
   "source": [
    "folder = \"./texts/Torah\"\n",
    "seferFilenames = getFilePaths(folder)\n",
    "allWords, allLetters, allNgrams = runOnWholeTorah(seferFilenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lips', 76863),\n",
       " ('throat', 73615),\n",
       " ('teeth', 62542),\n",
       " ('palate', 50390),\n",
       " ('tongue', 41753)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLetters.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lips_palate_tongue_tongue_palate_throat_teeth', 1),\n",
       " ('teeth_lips_throat_palate_teeth_lips', 1),\n",
       " ('lips_throat_palate_tongue_palate_teeth_lips', 1),\n",
       " ('lips_teeth_teeth_lips_tongue_lips', 1),\n",
       " ('palate_throat_teeth_lips_teeth_lips', 1),\n",
       " ('teeth_throat_teeth_palate_lips_lips', 1),\n",
       " ('teeth_lips_teeth_teeth_palate_lips', 1),\n",
       " ('lips_lips_teeth_throat_teeth_teeth', 1),\n",
       " ('lips_teeth_throat_palate_palate_teeth_throat', 1),\n",
       " ('teeth_teeth_palate_throat_teeth', 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords.most_common(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tongue_tongue_teeth', 274),\n",
       " ('lips_lips_lips', 256),\n",
       " ('tongue_teeth_teeth', 249),\n",
       " ('tongue_teeth_tongue', 244),\n",
       " ('teeth_tongue_tongue', 211),\n",
       " ('teeth_teeth_tongue', 154),\n",
       " ('throat_throat_throat', 146),\n",
       " ('palate_throat_throat', 125),\n",
       " ('palate_palate_palate', 78),\n",
       " ('tongue_tongue_tongue', 69)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allNgrams.most_common()[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic histogram/breakdowns:\n",
    "    \n",
    "#### Letters, pairs of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talmud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting filenames...\n",
      "There are 37 masechtot.\n"
     ]
    }
   ],
   "source": [
    "## Load:\n",
    "folder = \"texts/Talmud\"\n",
    "masechetFilenames = getFilePaths(folder, hebrewOrEnglish = \"English\")\n",
    "print (\"There are {} masechtot.\".format(len(masechetFilenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yikes\n",
    "def masechetFromFilename(masechetFilename):\n",
    "    \n",
    "    splitName = masechetFilename.split(\"/\")\n",
    "    nextIndex = splitName.index(\"English\")\n",
    "    masechetName = splitName[nextIndex - 1]\n",
    "    \n",
    "    return masechetName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran the spaCy code below to get all people in the Talmud. That had lots of false positives (e.g. \"Leviticus 8:11\", \"chews ginger\"), so took all lines with \"Rav\", \"Rabb\", and \"The\" in them, to get most of the true hits.\n",
    "(Missing people like \"Berurya\" or \"Ḥoni HaMe’aggel\" with this, though.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1666 rabbis from the Talmud.\n"
     ]
    }
   ],
   "source": [
    "rabbis = set([person.strip() for person in open(\"RavRabbThe.txt\", \"r\")])\n",
    "print(\"Working with {} rabbis from the Talmud.\".format(len(rabbis)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niddah\n",
      "Chagigah\n",
      "Yoma\n",
      "Rosh Hashanah\n",
      "Moed Katan\n",
      "Beitzah\n",
      "Sukkah\n",
      "Megillah\n",
      "Taanit\n",
      "Pesachim\n",
      "Shabbat\n",
      "Eruvin\n",
      "Berakhot\n",
      "Horayot\n",
      "Avodah Zarah\n",
      "Bava Batra\n",
      "Shevuot\n",
      "Sanhedrin\n",
      "Bava Metzia\n",
      "Bava Kamma\n",
      "Makkot\n",
      "Sotah\n",
      "Kiddushin\n",
      "Nazir\n",
      "Yevamot\n",
      "Gittin\n",
      "Ketubot\n",
      "Nedarim\n",
      "Zevachim\n",
      "Meilah\n",
      "Bekhorot\n",
      "Temurah\n",
      "Keritot\n",
      "Menachot\n",
      "Arakhin\n",
      "Chullin\n",
      "Tamid\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "lineNumber = 0\n",
    "people = set()\n",
    "rabbisToMasechet = defaultdict(Counter)\n",
    "masechetToRabbis = defaultdict(Counter)\n",
    "\n",
    "for filename in masechetFilenames:\n",
    "    \n",
    "    masechetName = masechetFromFilename(filename)\n",
    "    print (\"\\r{}\\r\".format(masechetName))\n",
    "    reader = open(filename, \"r\")\n",
    "    for line in reader:\n",
    "        \n",
    "        ### Skip the header info, and the whitespace/daf numbers\n",
    "        lineNumber += 1\n",
    "        if lineNumber < 21 or len(line) < 13:\n",
    "            continue\n",
    "        line = re.sub('<[^<]+?>', '', line) # ayy https://stackoverflow.com/a/4869782\n",
    "\n",
    "        ### Incredible https://spacy.io/usage/linguistic-features#named-entities\n",
    "        doc = nlp(line)            \n",
    "        for entity in doc.ents:\n",
    "            \n",
    "            ### First pass: get all the people (lots of false positives):\n",
    "#             if entity.label_ == \"PERSON\" and entity.text in rabbis:\n",
    "#                 people.add(entity)\n",
    "                \n",
    "            ### Next round: use that to make an edited list:\n",
    "            if entity.label_ == \"PERSON\" and entity.text in rabbis:\n",
    "                rabbisToMasechet[entity.text][masechetName] += 1\n",
    "                masechetToRabbis[masechetName][entity.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First round: save all the spaCy results.\n",
    "\n",
    "# peopleToText = {name.text for name in people}\n",
    "# with open(\"talmudPeople.txt\", \"w\") as out:\n",
    "#     out.write(\"\\n\".join(peopleToText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second round: save the more accurate counts.\n",
    "\n",
    "sortedRabbis = sorted(rabbis)\n",
    "with open(\"RabbiCounts.tsv\", \"w\") as out:\n",
    "    \n",
    "    masechtot = sorted(masechetToRabbis)\n",
    "    out.write(\"\\t{}\\n\".format(\"\\t\".join(masechtot)))\n",
    "    \n",
    "    for rabbi in sortedRabbis:\n",
    "        \n",
    "        rabbiCounts = rabbisToMasechet[rabbi]\n",
    "        sortedCounts = [str(rabbiCounts[masechet]) for masechet in masechtot]\n",
    "        \n",
    "        out.write(\"{r}\\t{c}\\n\".format(r = rabbi, c = \"\\t\".join(sortedCounts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Matching (without spaCy)\n",
    "\n",
    "Alternative (quicker) way that doesn't use spaCy, so it doesn't do true entity recognition and just searches for any matches. Runs instantly, but counts \"Rav\" a bunch because it counts \"Rav x\" for Rav as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rabbisToMasechet = defaultdict(Counter)\n",
    "# masechetToRabbis = defaultdict(Counter)\n",
    "\n",
    "# for filename in masechetFilenames:\n",
    "        \n",
    "#     masechetName = masechetFromFilename(filename)\n",
    "#     print (\"\\r{}\\r\".format(masechetName))\n",
    "#     with open(filename, \"r\") as masechet:\n",
    "        \n",
    "#         text = masechet.read()\n",
    "#         for rabbi in rabbis:\n",
    "#             appearances = text.count(rabbi)\n",
    "            \n",
    "#             if appearances != 0:\n",
    "#                 rabbisToMasechet[rabbi][masechetName] += appearances\n",
    "#                 masechetToRabbis[masechetName][rabbi] += appearances\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Big to print\n",
    "# print(rabbisToMasechet)\n",
    "# print(masechetToRabbis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rabbi Yehuda's most common:\n",
      " \tShabbat: 446; Pesachim: 409; Chullin: 406; Eruvin: 395; Menachot: 322\n",
      "Berakhot's most common:\n",
      " \tRabbi Yoḥanan: 292; Rabbi Yehuda: 222; Rav: 219; Rava: 122; Rabbi Yosei: 110\n",
      "\n",
      "Rabbi Yehuda's least common:\n",
      " \tHorayot: 48; Rosh Hashanah: 40; Chagigah: 37; Meilah: 16; Tamid: 2\n",
      "Berakhot's least common:\n",
      " \tRav Sama: 1; Rabbi Yosei bar Yehuda: 1; Rabbi Parnakh: 1; Rav Huna bar Berekhya: 1; Rabbi Elazar HaKappar: 1; Rabbi Yosei ben Keifar: 1; Zekharya ben Kevutal: 1; Zekharya ben: 1; the Sages of the Mishna: 1; Rav Yehuda bar Zevida: 1\n"
     ]
    }
   ],
   "source": [
    "def formattedCounts(counts):\n",
    "    \n",
    "    formatted = \"\\t\" + \"; \".join([\"{}: {}\".format(value, count) for value, count in counts])\n",
    "    return formatted\n",
    "    \n",
    "rabbi = \"Rabbi Yehuda\"\n",
    "masechet = \"Berakhot\"\n",
    "### Most common:\n",
    "\n",
    "print(\"{}'s most common:\\n\".format(rabbi), formattedCounts(rabbisToMasechet[rabbi].most_common(5)))\n",
    "print(\"{}'s most common:\\n\".format(masechet), formattedCounts(masechetToRabbis[masechet].most_common(5)))\n",
    "print()\n",
    "\n",
    "### Least common:\n",
    "\n",
    "print(\"{}'s least common:\\n\".format(rabbi), formattedCounts(rabbisToMasechet[rabbi].most_common()[-5:]))\n",
    "print(\"{}'s least common:\\n\".format(masechet), formattedCounts(masechetToRabbis[masechet].most_common()[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full counts across the whole Talmud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rabbisFullCounts = Counter()\n",
    "\n",
    "for rabbi, masechetCounts in rabbisToMasechet.items():\n",
    "    \n",
    "    masechetTotalCounts = sum(masechetCounts.values())\n",
    "    rabbisFullCounts[rabbi] += masechetTotalCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rabbi Yoḥanan', 6473),\n",
       " ('Rabbi Yehuda', 6335),\n",
       " ('Rav', 5819),\n",
       " ('Rabbi Shimon', 3915),\n",
       " ('Rabbi Meir', 3756),\n",
       " ('Rabbi Yosei', 3589),\n",
       " ('Rabbis', 3552),\n",
       " ('Rava', 3507),\n",
       " ('Rabbi Eliezer', 3123),\n",
       " ('Rabbi Yehuda HaNasi', 3079),\n",
       " ('Rabbi Akiva', 2926),\n",
       " ('Rabbi Elazar', 2712),\n",
       " ('Rav Huna', 2481),\n",
       " ('Rav Yehuda', 2432),\n",
       " ('Rav Ashi', 2241),\n",
       " ('Rav Pappa', 2027),\n",
       " ('Rav Yosef', 1965),\n",
       " ('Rav Ḥisda', 1742),\n",
       " ('Rabba', 1664),\n",
       " ('Rabbi Yishmael', 1583),\n",
       " ('Rabbi Ḥiyya', 1421),\n",
       " ('Rabbi Yehoshua', 1344),\n",
       " ('Rabbi Ḥanina', 1171),\n",
       " ('Rabbi Zeira', 1148),\n",
       " ('Rav Sheshet', 1029),\n",
       " ('Rabban Gamliel', 848),\n",
       " ('Rav Kahana', 764),\n",
       " ('Shimon ben Gamliel', 717),\n",
       " ('Ravina', 699),\n",
       " ('Rabbi Yehoshua ben Levi', 685)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rabbisFullCounts.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general)",
   "language": "python",
   "name": "general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
